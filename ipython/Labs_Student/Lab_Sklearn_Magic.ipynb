{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this lab we'll demonstrate several common techniques and helpful tools used in a model building process:\n",
    "\n",
    "- Use Sklearn to generate polynomial features and rescale them\n",
    "- Create folds for cross-validation\n",
    "- Perform a grid search to optimize hyper-parameters using cross-validation\n",
    "- Create pipelines to perform grids search in less code\n",
    "- Improve upon a baseline model incrementally by adding in more complexity\n",
    "\n",
    "This lab will require using several Sklearn classes. It would be helpful to refer to appropriate documentation:\n",
    "- http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "- http://scikit-learn.org/stable/modules/pipeline.html#pipeline\n",
    "\n",
    "Also, here is a helpful tutorial that explains how to use much of the above:\n",
    "- https://civisanalytics.com/blog/data-science/2016/01/06/workflows-python-using-pipeline-gridsearchcv-for-compact-code/\n",
    "\n",
    "Like always, let's first load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['revenue', 'outcalls', 'incalls', 'months', 'eqpdays', 'webcap',\n",
       "       'marryyes', 'travel', 'pcown', 'creditcd', 'retcalls', 'churndep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cwd = os.getcwd()\n",
    "datadir = '/'.join(cwd.split('/')[0:-1]) + '/data/'\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(datadir + 'Cell2Cell_data.csv', header=0, sep=',')\n",
    "\n",
    "#Randomly sort the data:\n",
    "data = data.sample(frac = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to prep the data. From prior analysis (Churn Case Study) we learned that we can drop a few variables, as they are either highly redundant or don't carry a strong relationship with the outcome.\n",
    "\n",
    "After dropping, we're going to use the SkLearn KFold class to set up cross validation fold indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prior analysis (from Churn Case study) has shown that we can drop a few redundant variables\n",
    "#We want to drop a few to speed up later calculations\n",
    "dropvar_list = ['incalls', 'creditcd', 'marryyes', 'travel', 'pcown']\n",
    "data_subset = data.drop(dropvar_list, 1)\n",
    "\n",
    "#Set up X and Y\n",
    "X = data_subset.drop('churndep', 1)\n",
    "Y = data_subset['churndep']\n",
    "\n",
    "#Use Kfold to create 4 folds\n",
    "kfolds = KFold(data_subset.shape[0], n_folds = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's use cross-validation to build a baseline model. We're going to use LR with no feature pre-processing. We're going to look at both L1 and L2 regularization with different weights. We can do this very succinctly with SkLearns GridSearchCV package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585720326242\n"
     ]
    }
   ],
   "source": [
    "#1st, set up a paramater grid\n",
    "param_grid_lr = {'C':[10**i for i in range(-3, 3)], 'penalty':['l1', 'l2']}\n",
    "\n",
    "#2nd, call the GridSearchCV class, use LogisticRegression and 'roc_auc' for scoring\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), param_grid_lr, cv = kfolds, scoring = 'roc_auc') \n",
    "lr_grid_search.fit(X, Y)\n",
    "\n",
    "#3rd, get the score of the best model and print it\n",
    "best_1 = lr_grid_search.best_score_\n",
    "print(best_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next let's look at the best-estimator chosen to see what the parameters were\n",
    "lr_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can beat this by standardizing the features. We'll approach this using the GridSearchCV class but also build a pipeline. Later we'll extend the pipeline to allow for feature engineering as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587496112303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "#Build a list of steps, where the first is StandardScaler and the second is LogisticRegression\n",
    "#The last step should be an estimator.\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#Now set up the parameter grid, paying close to the correct convention here\n",
    "parameters_scaler = dict(lr__C = [10**i for i in range(-3, 3)],\n",
    "                  lr__penalty = ['l1', 'l2'])\n",
    "\n",
    "#Now run another grid search\n",
    "lr_grid_search_scaler = GridSearchCV(pipeline, param_grid = parameters_scaler, cv = kfolds, scoring = 'roc_auc')\n",
    "lr_grid_search_scaler.fit(X, Y)\n",
    "\n",
    "\n",
    "#Again, print the score of the best model\n",
    "best_2 = lr_grid_search_scaler.best_score_\n",
    "print(best_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see the model after scaling. Did the optimal parameters change?\n",
    "lr_grid_search_scaler.best_estimator_.steps[-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built a pipeline estimator that performs feature scaling and then logistic regression, let's add to it a feature engineering step. We'll then again use GridSearchCV to find an optimal parameter configuration and see if we can beat our best score above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592645611533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "# Step 1 - PolynomialFeatures\n",
    "# Step 2 - StandardScaler\n",
    "# Step 3 - LogisticRegression\n",
    "\n",
    "steps_poly = [('polyfeat', PolynomialFeatures()),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline_poly = Pipeline(steps_poly)\n",
    "\n",
    "#Now set up a new parameter grid, use the same paramaters used above for logistic regression, but add polynomial features up to degree 3. \n",
    "parameters_poly = dict(polyfeat__degree = [1, 2],\n",
    "                       polyfeat__interaction_only = [True, False],\n",
    "                       lr__C = [10**i for i in range(-3, 3)],\n",
    "                       lr__penalty = ['l1', 'l2'])\n",
    "\n",
    "#Now run another grid search\n",
    "lr_grid_search_poly = GridSearchCV(pipeline_poly, param_grid = parameters_poly, cv = kfolds, scoring = 'roc_auc')\n",
    "\n",
    "lr_grid_search_poly.fit(X, Y)\n",
    "best_3 = lr_grid_search_poly.best_score_\n",
    "print(best_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polyfeat',\n",
       "  PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)),\n",
       " ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('lr',\n",
       "  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the best estimator, stepwise\n",
    "lr_grid_search_poly.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a bar chart to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10c502470>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFvCAYAAABJkw0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWJIkSQLg/wOhCCXH8h26/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c4f17b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = np.array([best_1, best_2, best_3])\n",
    "labs = ['LR', 'Scaler-LR', 'Poly-Scaler-LR']\n",
    "\n",
    "fig = plt.figure(facecolor = 'w', figsize = (12, 6))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "width = 0.25\n",
    "ind = np.arange(3)\n",
    "rec = ax.bar(ind + width, results, width, color='r')\n",
    "\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(labs, size = 14)\n",
    "ax.set_ylim([0.5, max(results)*1.1])\n",
    "\n",
    "plt.plot(np.arange(4), max(results) * np.ones(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
